{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,glob\n",
    "from collections import defaultdict, Counter\n",
    "import random, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(message):\n",
    "    message = message.lower()\n",
    "    all_words = re.findall(\"[a-z0-9]+\",message)\n",
    "    return set(all_words)\n",
    "\n",
    "def count_words(training_set):\n",
    "    \"\"\"zbior treningowy to para (message,is_spam)\"\"\"\n",
    "    counts = defaultdict(lambda: [0,0])\n",
    "    for message, is_spam in training_set:\n",
    "        for word in tokenize(message):\n",
    "            counts[word][0 if is_spam else 1] += 1\n",
    "    return counts\n",
    "\n",
    "def word_probabilities(counts,total_spams,total_non_spams,k=0.5):\n",
    "    \"\"\"zwrocenie 3-elementowej listy zawierajace slowo, prawdopodobienstwo wystapienia w spamie i prawdopodobienstwa nie bycia spamem\"\"\"\n",
    " \n",
    "    return [(w,(spam +k)/(total_spams + 2 *k),\n",
    "            (non_spam + k)/(total_non_spams +2 * k))\n",
    "            for w,(spam,non_spam) in counts.items()]\n",
    "\n",
    "def spam_probability(word_probs, message):\n",
    "    \"\"\"prawdopodbienstwo wystapienia slow w celu przypisania prawdopodobienstw do wiadomosci\"\"\"\n",
    "    message_words = tokenize(message)\n",
    "    log_prob_if_spam = log_prob_if_not_spam = 0.0\n",
    "\n",
    "    for word, prob_if_spam, prob_if_not_spam in word_probs:\n",
    "        if word in message_words:\n",
    "            log_prob_if_spam += math.log(prob_if_spam)\n",
    "            log_prob_if_not_spam += math.log(prob_if_not_spam)\n",
    "        else:\n",
    "            log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
    "            log_prob_if_not_spam += math.log(1.0 - prob_if_not_spam)\n",
    "\n",
    "    prob_if_spam = math.exp(log_prob_if_spam)\n",
    "    prob_if_not_spam = math.exp(log_prob_if_not_spam)\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_not_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self,k=0.5):\n",
    "        self.k = k\n",
    "        self.word_probs = []\n",
    "        \n",
    "    def train(self,training_set):\n",
    "        num_spams = len([is_spam for message, is_spam in training_set if is_spam])\n",
    "        num_non_spams = len(training_set) - num_spams\n",
    "        \n",
    "        #przetworzenie zbioru danych\n",
    "        word_counts = count_words(training_set)\n",
    "        self.word_probs = word_probabilities(word_counts,num_spams,num_non_spams,self.k)\n",
    "        \n",
    "    def classify(self,message):\n",
    "        return spam_probability(self.word_probs,message)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"D:\\\\studia\\\\spam\\\\*\\\\*\\\\**\"\n",
    "\n",
    "data = []\n",
    "\n",
    "for fn in glob.glob(path):\n",
    "    is_spam = \"ham\" not in fn\n",
    "\n",
    "    with open(fn,'r',encoding='ISO-8859-1') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"Subject:\"):\n",
    "                subject = re.sub(r\"^Subject: \",\"\", line).strip()\n",
    "                data.append((subject, is_spam))\n",
    "\n",
    "#metoda z pliku machine_learning\n",
    "def split_data(data, prob):\n",
    "    \"\"\"split data into fractions [prob, 1 - prob]\"\"\"\n",
    "    results = [], []\n",
    "    for row in data:\n",
    "        results[0 if random.random() < prob else 1].append(row)\n",
    "    return results\n",
    "\n",
    "#dodatkowa metoda, ktora na podstawie twierdzenia bayesa oblicza prawdopodobienstwa spamu\n",
    "def p_spam_given_word(word_prob):\n",
    "    word, prob_if_spam, prob_if_not_spam = word_prob\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_not_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spammiest_hams [('FREE SHIPPING! No Minimum Purchase* at Buy.com', False, 0.9814624012504162), ('=?iso-8859-1?Q?Matrox_Parhelia=99_now_available?=', False, 0.9871924463035405), ('Cost price Guinness, Budweiser and selected spirits at tesco.ie', False, 0.9898231096678337), ('=?iso-2022-jp?B?GyRCRnxLXDhsJE43b0w+IUolNSVWJTglJyUvJUghSyEhJTkbKEI=?=', False, 0.9910012705992947), ('Four free e-mailers reviewed, Get the gear you need to burn DVDs', False, 0.9999182370913647)] \n",
      "\n",
      "hammiest_spams [('I was so scared... my very first DP', True, 2.063843818875714e-05), ('Not too old to put out!                   26792', True, 0.00041945396601744613), ('The Flight to Safety is Upon Us', True, 0.000987253170881586), (\"UK's Leading PC Specialist\", True, 0.0015306190853744126), ('Looking for property in SPAIN?', True, 0.002282369371051323)] \n",
      "\n",
      "spammiest_words [('sale', 0.026501766784452298, 0.00029291154071470416), ('need', 0.026501766784452298, 0.00029291154071470416), ('zzzz', 0.030035335689045935, 0.00029291154071470416), ('systemworks', 0.03356890459363958, 0.00029291154071470416), ('adv', 0.04770318021201413, 0.00029291154071470416)] \n",
      "\n",
      "hammiest_words [('spambayes', 0.0017667844522968198, 0.05008787346221441), ('zzzzteana', 0.0017667844522968198, 0.049502050380785), ('satalk', 0.0017667844522968198, 0.048916227299355595), ('was', 0.0017667844522968198, 0.040714704159343876), ('users', 0.0017667844522968198, 0.03368482718219098)]\n"
     ]
    }
   ],
   "source": [
    "#podzielenie zbioru na treningowy i testowy oraz zbudowanie klasyfikatora\n",
    "random.seed(0)\n",
    "train_data,test_data = split_data(data,0.6)\n",
    "\n",
    "classifier = NaiveBayesClassifier()\n",
    "classifier.train(train_data)\n",
    "\n",
    "classified = [(subject, is_spam,classifier.classify(subject)) for subject,is_spam in test_data]\n",
    "counts = Counter((is_spam,spam_probability > 0.5) for _,is_spam,spam_probability in classified)\n",
    "\n",
    "classified.sort(key=lambda row: row[2])\n",
    "#najwieksze prawdopodbienstwo spamu wsrod wiadomosci niebedacych spamem\n",
    "\n",
    "spammiest_hams = list(filter(lambda row: not row[1], classified))[-5:]\n",
    "\n",
    "#najmniejsze prawdopodobienstwo spamu wsrod wiadomosci bedacych spamem\n",
    "\n",
    "hammiest_spams = list(filter(lambda row: row[1], classified))[:5]\n",
    "\n",
    "print(\"spammiest_hams\", spammiest_hams,'\\n')\n",
    "print(\"hammiest_spams\", hammiest_spams,'\\n')\n",
    "\n",
    "words = sorted(classifier.word_probs, key=p_spam_given_word)\n",
    "\n",
    "#najwieksze prawdopodbienstwo spamu\n",
    "spammiest_words = words[-5:]\n",
    "#najwieksze prawdopodobienstwo ze nie jest spamem\n",
    "hammiest_words = words[:5]\n",
    "\n",
    "print(\"spammiest_words\", spammiest_words,'\\n')\n",
    "print(\"hammiest_words\", hammiest_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
